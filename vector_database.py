# vector_database.py - å‘é‡æ•°æ®åº“ç®¡ç†å™¨

import chromadb
from typing import List, Dict, Optional
from tqdm import tqdm
import config
from data_loader import KnowledgeDataLoader
from embedding_client import EmbeddingClient

class VectorDatabaseManager:
    """å‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = chromadb.PersistentClient(path=config.CHROMA_DB_PATH)
        self.collection = None
        self.embedding_client = EmbeddingClient()
        
    def initialize_collection(self, reset: bool = False):
        """åˆå§‹åŒ–æˆ–é‡ç½®é›†åˆ"""
        if reset and self.collection:
            try:
                self.client.delete_collection(name=config.COLLECTION_NAME)
                print(f"ğŸ—‘ å·²åˆ é™¤ç°æœ‰é›†åˆ: {config.COLLECTION_NAME}")
            except:
                pass
        
        self.collection = self.client.get_or_create_collection(
            name=config.COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"}
        )
        
        print(f"âœ… é›†åˆåˆå§‹åŒ–å®Œæˆ: {config.COLLECTION_NAME}")
        print(f"   - å½“å‰æ–‡æ¡£æ•°é‡: {self.collection.count()}")
        
    def triple_to_embedding_text(self, triple: tuple, schema: tuple) -> str:
        """
        å°†ä¸‰å…ƒç»„å’ŒSchemaè½¬æ¢ä¸ºç”¨äºåµŒå…¥çš„ç®€æ´æ–‡æœ¬
        æ–°ç³»ç»Ÿï¼šä¿æŒä¿¡æ¯å®Œæ•´æ€§çš„åŒæ—¶ç®€åŒ–è¡¨ç¤º
        """
        sub, rel, obj = triple
        schema_sub, schema_rel, schema_obj = schema
        
        # æ¸…ç†å®ä½“åç§°
        sub_clean = sub.replace('_', ' ')
        obj_clean = obj.replace('_', ' ')
        
        # ç®€æ´ä½†ä¿¡æ¯å®Œæ•´çš„è¡¨ç¤º
        return f"{sub_clean} {rel} {obj_clean}. Types: {schema_sub} {schema_rel} {schema_obj}."
    
    def populate_database(self, knowledge_entries: Optional[List[Dict]] = None):
        """å¡«å……å‘é‡æ•°æ®åº“"""
        if not self.collection:
            self.initialize_collection()
        
        # å¦‚æœæ²¡æœ‰æä¾›æ•°æ®ï¼Œåˆ™åŠ è½½æ•°æ®
        if knowledge_entries is None:
            loader = KnowledgeDataLoader()
            knowledge_entries = loader.get_knowledge_entries()
        
        if not knowledge_entries:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°çŸ¥è¯†æ¡ç›®")
            return
        
        print(f"ğŸ”„ å¼€å§‹å¡«å……æ•°æ®åº“ï¼Œå…± {len(knowledge_entries)} ä¸ªæ¡ç›®")
        
        # å‡†å¤‡æ•°æ®
        ids = [entry['id'] for entry in knowledge_entries]
        documents = [self.triple_to_embedding_text(entry["triple"], entry["schema"]) 
                    for entry in knowledge_entries]
        
        # å‡†å¤‡å…ƒæ•°æ®ï¼ˆä¿å­˜å®Œæ•´çš„ä¸‰å…ƒç»„å’ŒSchemaä¿¡æ¯ï¼‰
        metadatas = [
            {
                # åŸå§‹ä¸‰å…ƒç»„
                "sub": entry["triple"][0], 
                "rel": entry["triple"][1], 
                "obj": entry["triple"][2],
                # Schemaä¿¡æ¯
                "sub_type": entry["schema"][0], 
                "rel_type": entry["schema"][1], 
                "obj_type": entry["schema"][2],
                # é¢å¤–ä¿¡æ¯
                "source_file": entry.get("source_file", ""),
                "text": entry.get("text", "")
            } 
            for entry in knowledge_entries
        ]
        
        # åˆ†æ‰¹å¤„ç†
        batch_size = config.BATCH_SIZE
        
        for i in tqdm(range(0, len(ids), batch_size), desc="åµŒå…¥å¤„ç†"):
            batch_ids = ids[i:i+batch_size]
            batch_documents = documents[i:i+batch_size]
            batch_metadatas = metadatas[i:i+batch_size]
            
            # è·å–åµŒå…¥å‘é‡
            batch_embeddings = self.embedding_client.get_embeddings_batch(batch_documents)
            
            if batch_embeddings:
                self.collection.add(
                    ids=batch_ids,
                    embeddings=batch_embeddings,
                    documents=batch_documents,
                    metadatas=batch_metadatas
                )
            else:
                print(f"âš  è·³è¿‡æ‰¹æ¬¡ {i}ï¼ŒåµŒå…¥å¤±è´¥")
        
        print(f"âœ… æ•°æ®åº“å¡«å……å®Œæˆï¼Œæ€»æ¡ç›®æ•°: {self.collection.count()}")
    
    def query_database(self, query: str, n_results: int = 5) -> List[Dict]:
        """æŸ¥è¯¢å‘é‡æ•°æ®åº“ - å¢å¼ºæŸ¥è¯¢ç­–ç•¥"""
        if not self.collection:
            print("âŒ é›†åˆæœªåˆå§‹åŒ–")
            return []
        
        # å¢å¼ºæŸ¥è¯¢ - ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“
        enhanced_queries = self._generate_query_variants(query)
        
        all_results = []
        
        # å¯¹æ¯ä¸ªæŸ¥è¯¢å˜ä½“è¿›è¡Œæ£€ç´¢
        for enhanced_query in enhanced_queries:
            query_embedding = self.embedding_client.get_embeddings_batch([enhanced_query])
            if not query_embedding:
                continue
            
            # æ‰§è¡ŒæŸ¥è¯¢
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=n_results
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            if results and results['ids'][0]:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    
                    result_item = {
                        'id': results['ids'][0][i],
                        'triple': (metadata['sub'], metadata['rel'], metadata['obj']),
                        'schema': (metadata['sub_type'], metadata['rel_type'], metadata['obj_type']),
                        'distance': results['distances'][0][i],
                        'document': results['documents'][0][i],
                        'text': metadata.get('text', ''),
                        'source_file': metadata.get('source_file', ''),
                        'query_variant': enhanced_query
                    }
                    all_results.append(result_item)
        
        # å»é‡å¹¶æŒ‰ç›¸ä¼¼åº¦æ’åº
        unique_results = self._deduplicate_and_rank(all_results, query)
        
        return unique_results[:n_results]
    
    def _generate_query_variants(self, query: str) -> List[str]:
        """ç”ŸæˆæŸ¥è¯¢å˜ä½“ä»¥æé«˜æ£€ç´¢è´¨é‡"""
        variants = [query]  # åŸå§‹æŸ¥è¯¢
        
        query_lower = query.lower()
        
        # é’ˆå¯¹ä¸åŒé—®é¢˜ç±»å‹ç”Ÿæˆå˜ä½“
        if 'who is the leader' in query_lower or 'who leads' in query_lower:
            # é¢†å¯¼è€…é—®é¢˜çš„å˜ä½“
            if 'belgium' in query_lower:
                variants.extend([
                    "Belgium leader president king",
                    "Belgium head of state government",
                    "Belgium prime minister president"
                ])
            else:
                # æå–å›½å®¶å
                words = query.split()
                for word in words:
                    if word.lower() not in ['who', 'is', 'the', 'leader', 'of', '?']:
                        variants.extend([
                            f"{word} leader",
                            f"{word} president",
                            f"{word} head of state"
                        ])
        
        elif 'where is' in query_lower and 'located' in query_lower:
            # ä½ç½®é—®é¢˜çš„å˜ä½“
            if 'airport' in query_lower:
                # æå–æœºåœºå
                words = query.split()
                airport_name = ""
                for i, word in enumerate(words):
                    if 'airport' in word.lower():
                        # è·å–æœºåœºåç§°
                        if i > 0:
                            airport_name = words[i-1]
                        break
                
                if airport_name:
                    variants.extend([
                        f"{airport_name} location country",
                        f"{airport_name} airport location",
                        f"{airport_name} situated in"
                    ])
        
        elif 'what type' in query_lower:
            # ç±»å‹é—®é¢˜çš„å˜ä½“
            words = query.split()
            for word in words:
                if word.lower() not in ['what', 'type', 'of', 'entity', 'is', '?']:
                    variants.extend([
                        f"{word} type category",
                        f"{word} entity type"
                    ])
        
        return list(set(variants))  # å»é‡
    
    def _deduplicate_and_rank(self, results: List[Dict], original_query: str) -> List[Dict]:
        """å»é‡å¹¶é‡æ–°æ’åºç»“æœ"""
        # æŒ‰IDå»é‡
        seen_ids = set()
        unique_results = []
        
        for result in results:
            if result['id'] not in seen_ids:
                seen_ids.add(result['id'])
                unique_results.append(result)
        
        # é‡æ–°è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        for result in unique_results:
            result['relevance_score'] = self._calculate_relevance_score(result, original_query)
        
        # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
        unique_results.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        return unique_results
    
    def _calculate_relevance_score(self, result: Dict, query: str) -> float:
        """è®¡ç®—ç»“æœçš„ç›¸å…³æ€§åˆ†æ•°"""
        query_lower = query.lower()
        triple = result['triple']
        sub, rel, obj = triple
        
        score = 1 - result['distance']  # åŸºç¡€ç›¸ä¼¼åº¦åˆ†æ•°
        
        # æ ¹æ®é—®é¢˜ç±»å‹å’Œä¸‰å…ƒç»„å†…å®¹è°ƒæ•´åˆ†æ•°
        if 'leader' in query_lower:
            if 'leader' in rel.lower() or 'president' in rel.lower() or 'king' in rel.lower():
                score += 0.3  # æé«˜é¢†å¯¼å…³ç³»çš„åˆ†æ•°
        
        if 'where' in query_lower and 'located' in query_lower:
            if 'location' in rel.lower() or 'country' in rel.lower():
                score += 0.3  # æé«˜ä½ç½®å…³ç³»çš„åˆ†æ•°
        
        # æ£€æŸ¥å®ä½“åŒ¹é…
        query_words = query_lower.split()
        for word in query_words:
            if len(word) > 3:  # å¿½ç•¥çŸ­è¯
                if word in sub.lower() or word in obj.lower():
                    score += 0.2  # å®ä½“åŒ¹é…åŠ åˆ†
        
        return score
    
    def get_database_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.collection:
            return {"status": "Collection not initialized"}
        
        return {
            "collection_name": self.collection.name,
            "total_documents": self.collection.count(),
            "status": "ready"
        }

# æµ‹è¯•å‡½æ•°
def test_vector_database():
    """æµ‹è¯•å‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    db_manager = VectorDatabaseManager()
    
    # åˆå§‹åŒ–é›†åˆ
    db_manager.initialize_collection()
    
    # å¦‚æœæ•°æ®åº“ä¸ºç©ºï¼Œå¡«å……æ•°æ®
    if db_manager.collection.count() == 0:
        print("æ•°æ®åº“ä¸ºç©ºï¼Œå¼€å§‹å¡«å……...")
        db_manager.populate_database()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "Who is the leader of Belgium?"
    results = db_manager.query_database(test_query, n_results=3)
    
    print(f"\næµ‹è¯•æŸ¥è¯¢: {test_query}")
    print(f"æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")
    
    for i, result in enumerate(results, 1):
        print(f"  {i}. ä¸‰å…ƒç»„: {result['triple']}")
        print(f"     Schema: {result['schema']}")
        print(f"     è·ç¦»: {result['distance']:.4f}")

if __name__ == '__main__':
    test_vector_database()