# enhanced_qa_generator.py - å¢å¼ºçš„QAç”Ÿæˆå™¨

import json
import os
import xml.etree.ElementTree as ET
from typing import List, Dict, Optional, Tuple
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
import config
from enhanced_retrieval_engine import EnhancedRetrievalEngine
import random

class EnhancedQAGenerator:
    """å¢å¼ºçš„QAç”Ÿæˆå™¨ - ä½¿ç”¨å¢å¼ºæ£€ç´¢ç³»ç»Ÿï¼Œè·³è¿‡é‡å†™æ¨¡å—ï¼Œç›´æ¥ç”¨ä¸‰å…ƒç»„ç”ŸæˆQAå¯¹"""
    
    def __init__(self):
        self.openai_api_key = config.OPENAI_API_KEY
        self.output_dir = config.QA_OUTPUT_DIR
        self.train_dataset_path = config.DATASET_PATHS[0]
        self.retrieval_engine = EnhancedRetrievalEngine()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(self.output_dir).mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = Path(self.output_dir) / f"enhanced_qa_generation_log_{timestamp}.txt"
        self._init_log_file()
        
        # æ£€æŸ¥OpenAI APIå¯†é’¥
        if not self.openai_api_key or self.openai_api_key == "your-openai-api-key-here":
            print("âš  è­¦å‘Š: OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œå°†æ— æ³•ç”ŸæˆQAå¯¹")
            
        # é—®é¢˜ç±»å‹å®šä¹‰
        self.question_types = ['sub', 'obj', 'rel', 'type']
    
    def _init_log_file(self):
        """åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("å¢å¼ºQAç”Ÿæˆè¯¦ç»†æ—¥å¿—\n")
            f.write(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {self.log_file}")
    
    def _get_one_shot_example(self, question_type: str) -> str:
        """æ ¹æ®é—®é¢˜ç±»å‹è·å–One-shotç¤ºä¾‹"""
        examples = {
            'rel': """**Example:**
- Triple: (Amsterdam Airport Schiphol, location, Haarlemmermeer)
- Question: What is the relationship between Amsterdam Airport Schiphol and Haarlemmermeer?
- Answer: location""",
            
            'sub': """**Example:**
- Triple: (Amsterdam Airport Schiphol, location, Haarlemmermeer)  
- Question: What is located in Haarlemmermeer?
- Answer: Amsterdam Airport Schiphol""",
            
            'obj': """**Example:**
- Triple: (Amsterdam Airport Schiphol, location, Haarlemmermeer)
- Question: Where is Amsterdam Airport Schiphol located?
- Answer: Haarlemmermeer""",
            
            'type': """**Example:**
- Triple: (Amsterdam Airport Schiphol, location, Haarlemmermeer)
- Schema: (Airport, location, City)
- Question: What is Amsterdam Airport Schiphol?
- Answer: Airport"""
        }
        
        return examples.get(question_type, examples['obj'])  # é»˜è®¤ä½¿ç”¨objç¤ºä¾‹
    
    def _construct_enhanced_prompt(self, triple: Tuple, schema: Tuple, question_type: str, source_text: str) -> str:
        """æ„é€ å¢å¼ºçš„promptï¼ŒåŒ…å«One-shotç¤ºä¾‹"""
        
        one_shot_example = self._get_one_shot_example(question_type)
        
        # æ ¹æ®é—®é¢˜ç±»å‹æ„é€ ä¸åŒçš„prompt
        if question_type == 'rel':
            task_instruction = f"""Generate a question asking about the relationship between the subject and object in the triple.
The answer should be the predicate/relation."""
        elif question_type == 'sub':
            task_instruction = f"""Generate a question asking about what entity has the given relationship with the object.
The answer should be the subject."""
        elif question_type == 'obj':
            task_instruction = f"""Generate a question asking about what the subject is related to through the given relationship.
The answer should be the object."""
        elif question_type == 'type':
            task_instruction = f"""Generate a question asking about what type/category the subject entity belongs to.
The answer should be the subject's type from the schema."""
        else:
            task_instruction = "Generate a relevant question and answer based on the triple."
        
        # æ„é€ å®Œæ•´prompt
        if question_type == 'type' and schema:
            prompt = f"""You are an expert at generating high-quality question-answer pairs from knowledge graph triples.

{one_shot_example}

**Your Task:**
{task_instruction}

**Given Information:**
- Triple: {triple}
- Schema: {schema}
- Source Text: {source_text[:200]}...

**Instructions:**
1. Generate a natural, clear question based on the triple and schema
2. Provide a concise, accurate answer
3. Follow the example format above
4. Make the question sound natural and conversational

**Output Format:**
Question: [your question]
Answer: [your answer]"""
        else:
            prompt = f"""You are an expert at generating high-quality question-answer pairs from knowledge graph triples.

{one_shot_example}

**Your Task:**
{task_instruction}

**Given Information:**
- Triple: {triple}
- Source Text: {source_text[:200]}...

**Instructions:**
1. Generate a natural, clear question based on the triple
2. Provide a concise, accurate answer  
3. Follow the example format above
4. Make the question sound natural and conversational

**Output Format:**
Question: [your question]
Answer: [your answer]"""
        
        return prompt
    
    def _call_llm_for_qa_generation(self, prompt: str) -> Optional[Dict[str, str]]:
        """è°ƒç”¨LLMç”ŸæˆQAå¯¹"""
        try:
            # æ£€æŸ¥APIå¯†é’¥
            if not self.openai_api_key or self.openai_api_key == "your-openai-api-key-here":
                print("âš  OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹ŸQAç”Ÿæˆ")
                return self._generate_mock_qa_response(prompt)
            
            from openai import OpenAI
            client = OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert at generating high-quality question-answer pairs from knowledge graphs. Follow the instructions precisely and provide concise, accurate responses."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            content = response.choices[0].message.content.strip()
            return self._parse_qa_response(content)
            
        except Exception as e:
            print(f"âš  LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._generate_mock_qa_response(prompt)
    
    def _generate_mock_qa_response(self, prompt: str) -> Optional[Dict[str, str]]:
        """ç”Ÿæˆæ¨¡æ‹ŸQAå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        try:
            # ä»promptä¸­æå–ä¸‰å…ƒç»„ä¿¡æ¯
            if "Triple: (" in prompt:
                triple_start = prompt.find("Triple: (") + 9
                triple_end = prompt.find(")", triple_start)
                triple_str = prompt[triple_start:triple_end]
                parts = [p.strip() for p in triple_str.split(",")]
                
                if len(parts) >= 3:
                    sub, rel, obj = parts[0], parts[1], parts[2]
                    
                    # æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆæ¨¡æ‹ŸQA
                    if "relationship between" in prompt:
                        return {
                            'question': f"What is the relationship between {sub} and {obj}?",
                            'answer': rel
                        }
                    elif "What is located" in prompt or "asking about what entity has" in prompt:
                        return {
                            'question': f"What has {rel} relationship with {obj}?",
                            'answer': sub
                        }
                    elif "Where is" in prompt or "asking about what the subject is related to" in prompt:
                        return {
                            'question': f"What is {sub} {rel} to?",
                            'answer': obj
                        }
                    elif "What is" in prompt and "type" in prompt:
                        # ä»schemaä¸­æå–ç±»å‹
                        if "Schema: (" in prompt:
                            schema_start = prompt.find("Schema: (") + 9
                            schema_end = prompt.find(")", schema_start)
                            schema_str = prompt[schema_start:schema_end]
                            schema_parts = [p.strip() for p in schema_str.split(",")]
                            if schema_parts:
                                return {
                                    'question': f"What type of entity is {sub}?",
                                    'answer': schema_parts[0]
                                }
                        return {
                            'question': f"What is {sub}?",
                            'answer': "Entity"
                        }
            
            return {
                'question': "What is the main topic?",
                'answer': "Knowledge graph entity"
            }
            
        except Exception as e:
            print(f"âš  æ¨¡æ‹ŸQAç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def _parse_qa_response(self, content: str) -> Optional[Dict[str, str]]:
        """è§£æLLMå“åº”ï¼Œæå–é—®é¢˜å’Œç­”æ¡ˆ"""
        try:
            lines = content.strip().split('\n')
            question = None
            answer = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('Question:'):
                    question = line.replace('Question:', '').strip()
                elif line.startswith('Answer:'):
                    answer = line.replace('Answer:', '').strip()
            
            if question and answer:
                return {'question': question, 'answer': answer}
            else:
                print(f"âš  æ— æ³•è§£æQAå“åº”: {content}")
                return None
                
        except Exception as e:
            print(f"âš  è§£æQAå“åº”å¤±è´¥: {e}")
            return None
    
    def _enhanced_retrieve_for_qa(self, text: str) -> List[Dict]:
        """ä½¿ç”¨å¢å¼ºæ£€ç´¢ç³»ç»Ÿè·å–ç›¸å…³ä¸‰å…ƒç»„ï¼Œè·³è¿‡é‡å†™æ­¥éª¤"""
        try:
            # ä½¿ç”¨å¢å¼ºç³»ç»Ÿçš„å¤šé˜¶æ®µæ£€ç´¢åŠŸèƒ½
            retrieved_items = self.retrieval_engine.db_manager.multi_stage_retrieval(
                query=text, 
                n_results=5,  # æœ€ç»ˆè¿”å›5ä¸ªç»“æœ
                rerank_top_k=15  # ç¬¬ä¸€é˜¶æ®µæ£€ç´¢15ä¸ªï¼Œç„¶åé‡æ’
            )
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            enhanced_results = []
            for item in retrieved_items:
                enhanced_results.append({
                    'triple': item['triple'],
                    'schema': item.get('schema', None),
                    'distance': item['distance'],
                    'metadata': item.get('metadata', {}),
                    'document': item.get('document', ''),
                    'rerank_score': item.get('rerank_score', 0),
                    'detailed_scores': item.get('detailed_scores', {})
                })
            
            return enhanced_results
            
        except Exception as e:
            print(f"âš  å¢å¼ºæ£€ç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _generate_qa_from_text(self, text: str, entry_id: str) -> List[Dict]:
        """ä»æ–‡æœ¬ç”ŸæˆQAå¯¹çš„ä¸»è¦æ–¹æ³•"""
        qa_pairs = []
        
        try:
            # 1. ä½¿ç”¨å¢å¼ºæ£€ç´¢è·å–ç›¸å…³ä¸‰å…ƒç»„ï¼ˆè·³è¿‡é‡å†™ï¼‰
            retrieved_results = self._enhanced_retrieve_for_qa(text)
            
            if not retrieved_results:
                print(f"âš  æ–‡æœ¬ {entry_id} æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³ä¸‰å…ƒç»„")
                return qa_pairs
            
            # 2. ä¸ºæ¯ä¸ªæ£€ç´¢åˆ°çš„ä¸‰å…ƒç»„ç”Ÿæˆä¸åŒç±»å‹çš„QAå¯¹
            for i, result in enumerate(retrieved_results[:3]):  # é™åˆ¶å‰3ä¸ªç»“æœ
                triple = result['triple']
                schema = result.get('schema')
                
                # éšæœºé€‰æ‹©1-2ä¸ªé—®é¢˜ç±»å‹è¿›è¡Œç”Ÿæˆ
                selected_types = random.sample(self.question_types, k=random.randint(1, 2))
                
                for question_type in selected_types:
                    try:
                        # 3. æ„é€ å¢å¼ºpromptï¼ˆåŒ…å«One-shotç¤ºä¾‹ï¼‰
                        prompt = self._construct_enhanced_prompt(triple, schema, question_type, text)
                        
                        # 4. è°ƒç”¨LLMç”ŸæˆQAå¯¹
                        qa_result = self._call_llm_for_qa_generation(prompt)
                        
                        if qa_result:
                            qa_pair = {
                                'question': qa_result['question'],
                                'answer': qa_result['answer'],
                                'question_type': question_type,
                                'source_text': text,
                                'triple': triple,
                                'schema': schema,
                                'entry_id': entry_id,
                                'generation_method': 'enhanced_retrieval_with_oneshot',
                                'retrieval_distance': result['distance'],
                                'timestamp': datetime.now().isoformat()
                            }
                            
                            qa_pairs.append(qa_pair)
                            
                            # è®°å½•åˆ°æ—¥å¿—
                            self._log_qa_generation(entry_id, text, result, prompt, qa_pair, question_type)
                            
                    except Exception as e:
                        print(f"âš  ç”ŸæˆQAå¯¹å¤±è´¥ (ç±»å‹: {question_type}): {e}")
                        continue
            
            return qa_pairs
            
        except Exception as e:
            print(f"âš  å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™ (ID: {entry_id}): {e}")
            return qa_pairs
    
    def _log_qa_generation(self, entry_id: str, text: str, retrieval_result: Dict, 
                          prompt: str, qa_pair: Dict, question_type: str):
        """è®°å½•QAç”Ÿæˆè¿‡ç¨‹åˆ°æ—¥å¿—æ–‡ä»¶"""
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write("ğŸ”¸" + "=" * 78 + "ğŸ”¸\n")
                f.write(f"ğŸ“‹ æ¡ç›®ID: {entry_id}\n")
                f.write(f"ğŸ• æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ğŸ· é—®é¢˜ç±»å‹: {question_type}\n")
                f.write("-" * 80 + "\n")
                
                f.write("ğŸ“ è¾“å…¥æ–‡æœ¬:\n")
                f.write(f"{text[:300]}...\n")
                f.write("-" * 80 + "\n")
                
                f.write("ğŸ” æ£€ç´¢ç»“æœ:\n")
                f.write(f"ä¸‰å…ƒç»„: {retrieval_result['triple']}\n")
                f.write(f"Schema: {retrieval_result.get('schema', 'N/A')}\n")
                f.write(f"è·ç¦»: {retrieval_result['distance']:.4f}\n")
                f.write("-" * 80 + "\n")
                
                f.write("ğŸ’¬ æ„å»ºçš„Prompt:\n")
                f.write(f"{prompt[:500]}...\n")
                f.write("-" * 80 + "\n")
                
                f.write("âœ… ç”Ÿæˆçš„QAå¯¹:\n")
                f.write(f"é—®é¢˜: {qa_pair['question']}\n")
                f.write(f"ç­”æ¡ˆ: {qa_pair['answer']}\n")
                f.write("ğŸ”¸" + "=" * 78 + "ğŸ”¸\n\n")
                
        except Exception as e:
            print(f"âš  æ—¥å¿—è®°å½•å¤±è´¥: {e}")
    
    def generate_qa_dataset_from_texts(self, max_texts: int = None, output_filename: str = None) -> List[Dict]:
        """ä»trainæ•°æ®é›†æ–‡æœ¬ç”ŸæˆQAæ•°æ®é›†"""
        
        print(f"ğŸš€ å¼€å§‹å¢å¼ºQAç”Ÿæˆæµç¨‹")
        print(f"ğŸ“Š æµç¨‹: Text â†’ å¢å¼ºæ£€ç´¢ â†’ é‡æ’ â†’ è·³è¿‡é‡å†™ â†’ One-shot Prompt â†’ LLM â†’ QAå¯¹")
        
        # è·å–æ‰€æœ‰XMLæ–‡ä»¶
        xml_files = list(Path(self.train_dataset_path).glob("*.xml"))
        
        if not xml_files:
            print(f"âŒ åœ¨ {self.train_dataset_path} ä¸­æœªæ‰¾åˆ°XMLæ–‡ä»¶")
            return []
        
        # é™åˆ¶å¤„ç†æ•°é‡
        if max_texts:
            xml_files = xml_files[:max_texts]
        
        print(f"ğŸ“ æ‰¾åˆ° {len(xml_files)} ä¸ªXMLæ–‡ä»¶")
        
        all_qa_pairs = []
        output_path = Path(self.output_dir) / (output_filename or "enhanced_qa_dataset.json")
        
        # å¢é‡ä¿å­˜æ¨¡å¼
        processed_count = 0
        
        for xml_file in tqdm(xml_files, desc="å¤„ç†XMLæ–‡ä»¶"):
            try:
                # è§£æXMLæ–‡ä»¶
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                # æå–æ–‡æœ¬å†…å®¹
                text_elements = root.findall('.//text')
                
                for text_elem in text_elements:
                    text_content = text_elem.text
                    if text_content and len(text_content.strip()) > 50:
                        
                        entry_id = f"{xml_file.stem}_{len(all_qa_pairs)}"
                        
                        # ç”ŸæˆQAå¯¹
                        qa_pairs = self._generate_qa_from_text(text_content.strip(), entry_id)
                        
                        if qa_pairs:
                            all_qa_pairs.extend(qa_pairs)
                            
                            # æ¯å¤„ç†10ä¸ªæ–‡æœ¬ä¿å­˜ä¸€æ¬¡
                            if len(all_qa_pairs) % 10 == 0:
                                with open(output_path, 'w', encoding='utf-8') as f:
                                    json.dump(all_qa_pairs, f, ensure_ascii=False, indent=2)
                                print(f"ğŸ’¾ å·²ä¿å­˜ {len(all_qa_pairs)} ä¸ªQAå¯¹åˆ° {output_path}")
                
                processed_count += 1
                
            except Exception as e:
                print(f"âš  å¤„ç†æ–‡ä»¶ {xml_file} æ—¶å‡ºé”™: {e}")
                continue
        
        # æœ€ç»ˆä¿å­˜
        if all_qa_pairs:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(all_qa_pairs, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å¢å¼ºQAæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
            print(f"ğŸ“Š æ€»è®¡: {len(all_qa_pairs)} ä¸ªQAå¯¹")
            print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_path}")
            print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        
        return all_qa_pairs